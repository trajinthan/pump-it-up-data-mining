{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pumb-it-up",
      "provenance": [],
      "authorship_tag": "ABX9TyORT6hwkASWcBosYO7br9Xp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trajinthan/pump-it-up-data-mining/blob/main/pumb_it_up.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IfUrGb6MQFX"
      },
      "source": [
        "# **Load data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_MKlCxOL4-D"
      },
      "source": [
        "Authenticate with google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4X6X_7jKcGD"
      },
      "source": [
        "# from pydrive.auth import GoogleAuth\n",
        "# from pydrive.drive import GoogleDrive\n",
        "# from google.colab import auth\n",
        "# from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# auth.authenticate_user()\n",
        "# gauth = GoogleAuth()\n",
        "# gauth.credentials = GoogleCredentials.get_application_default()\n",
        "# drive = GoogleDrive(gauth)"
      ],
      "execution_count": 1068,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7OmOWxRqmju"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from typing import Dict, Tuple\n"
      ],
      "execution_count": 1069,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coONgIhrL5uS"
      },
      "source": [
        "Load data from google drive to colab work space according to the csv file id"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW9edJAYKkYG"
      },
      "source": [
        "\n",
        "# training_labels = drive.CreateFile({'id':'12QS3xedC7EoPS4Xj2cNVuwBSLnvbJMNM'}) \n",
        "# training_labels.GetContentFile('TrainLabel.csv')  \n",
        "train_label = pd.read_csv('TrainLabel.csv')\n",
        "\n",
        "# training_values = drive.CreateFile({'id':'1F4TZBjMRpTPkEbW7vjpQBIhl7Kp3QlEf'}) \n",
        "# training_values.GetContentFile('TrainValue.csv')  \n",
        "train_value = pd.read_csv('TrainValue.csv')\n",
        "\n",
        "# testing_labels = drive.CreateFile({'id':'1Y4Idhc-WeUTM5uQSjZOqyQ5r4ePgUD84'}) \n",
        "# testing_labels.GetContentFile('TestData.csv')  \n",
        "Xtest = pd.read_csv('TestData.csv')"
      ],
      "execution_count": 1070,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwtLwtEoQXKr"
      },
      "source": [
        "Merge training data values and respective training data labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vm_9zK_PZWa"
      },
      "source": [
        "train_data = train_value.merge(train_label, on='id')"
      ],
      "execution_count": 1071,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6CkrER4LSbh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "99b3684c-f2c4-4f94-b42e-2419f220db93"
      },
      "source": [
        "train_data.head().T"
      ],
      "execution_count": 1072,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <td>69572</td>\n",
              "      <td>8776</td>\n",
              "      <td>34310</td>\n",
              "      <td>67743</td>\n",
              "      <td>19728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>amount_tsh</th>\n",
              "      <td>6000</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date_recorded</th>\n",
              "      <td>2011-03-14</td>\n",
              "      <td>2013-03-06</td>\n",
              "      <td>2013-02-25</td>\n",
              "      <td>2013-01-28</td>\n",
              "      <td>2011-07-13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>funder</th>\n",
              "      <td>Roman</td>\n",
              "      <td>Grumeti</td>\n",
              "      <td>Lottery Club</td>\n",
              "      <td>Unicef</td>\n",
              "      <td>Action In A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gps_height</th>\n",
              "      <td>1390</td>\n",
              "      <td>1399</td>\n",
              "      <td>686</td>\n",
              "      <td>263</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>installer</th>\n",
              "      <td>Roman</td>\n",
              "      <td>GRUMETI</td>\n",
              "      <td>World vision</td>\n",
              "      <td>UNICEF</td>\n",
              "      <td>Artisan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>longitude</th>\n",
              "      <td>34.9381</td>\n",
              "      <td>34.6988</td>\n",
              "      <td>37.4607</td>\n",
              "      <td>38.4862</td>\n",
              "      <td>31.1308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>latitude</th>\n",
              "      <td>-9.85632</td>\n",
              "      <td>-2.14747</td>\n",
              "      <td>-3.82133</td>\n",
              "      <td>-11.1553</td>\n",
              "      <td>-1.82536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>wpt_name</th>\n",
              "      <td>none</td>\n",
              "      <td>Zahanati</td>\n",
              "      <td>Kwa Mahundi</td>\n",
              "      <td>Zahanati Ya Nanyumbu</td>\n",
              "      <td>Shuleni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>num_private</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>basin</th>\n",
              "      <td>Lake Nyasa</td>\n",
              "      <td>Lake Victoria</td>\n",
              "      <td>Pangani</td>\n",
              "      <td>Ruvuma / Southern Coast</td>\n",
              "      <td>Lake Victoria</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>subvillage</th>\n",
              "      <td>Mnyusi B</td>\n",
              "      <td>Nyamara</td>\n",
              "      <td>Majengo</td>\n",
              "      <td>Mahakamani</td>\n",
              "      <td>Kyanyamisa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>region</th>\n",
              "      <td>Iringa</td>\n",
              "      <td>Mara</td>\n",
              "      <td>Manyara</td>\n",
              "      <td>Mtwara</td>\n",
              "      <td>Kagera</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>region_code</th>\n",
              "      <td>11</td>\n",
              "      <td>20</td>\n",
              "      <td>21</td>\n",
              "      <td>90</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>district_code</th>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lga</th>\n",
              "      <td>Ludewa</td>\n",
              "      <td>Serengeti</td>\n",
              "      <td>Simanjiro</td>\n",
              "      <td>Nanyumbu</td>\n",
              "      <td>Karagwe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ward</th>\n",
              "      <td>Mundindi</td>\n",
              "      <td>Natta</td>\n",
              "      <td>Ngorika</td>\n",
              "      <td>Nanyumbu</td>\n",
              "      <td>Nyakasimbi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>population</th>\n",
              "      <td>109</td>\n",
              "      <td>280</td>\n",
              "      <td>250</td>\n",
              "      <td>58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>public_meeting</th>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recorded_by</th>\n",
              "      <td>GeoData Consultants Ltd</td>\n",
              "      <td>GeoData Consultants Ltd</td>\n",
              "      <td>GeoData Consultants Ltd</td>\n",
              "      <td>GeoData Consultants Ltd</td>\n",
              "      <td>GeoData Consultants Ltd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>scheme_management</th>\n",
              "      <td>VWC</td>\n",
              "      <td>Other</td>\n",
              "      <td>VWC</td>\n",
              "      <td>VWC</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>scheme_name</th>\n",
              "      <td>Roman</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Nyumba ya mungu pipe scheme</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>permit</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>construction_year</th>\n",
              "      <td>1999</td>\n",
              "      <td>2010</td>\n",
              "      <td>2009</td>\n",
              "      <td>1986</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>extraction_type</th>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>submersible</td>\n",
              "      <td>gravity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>extraction_type_group</th>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>submersible</td>\n",
              "      <td>gravity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>extraction_type_class</th>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>submersible</td>\n",
              "      <td>gravity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>management</th>\n",
              "      <td>vwc</td>\n",
              "      <td>wug</td>\n",
              "      <td>vwc</td>\n",
              "      <td>vwc</td>\n",
              "      <td>other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>management_group</th>\n",
              "      <td>user-group</td>\n",
              "      <td>user-group</td>\n",
              "      <td>user-group</td>\n",
              "      <td>user-group</td>\n",
              "      <td>other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>payment</th>\n",
              "      <td>pay annually</td>\n",
              "      <td>never pay</td>\n",
              "      <td>pay per bucket</td>\n",
              "      <td>never pay</td>\n",
              "      <td>never pay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>payment_type</th>\n",
              "      <td>annually</td>\n",
              "      <td>never pay</td>\n",
              "      <td>per bucket</td>\n",
              "      <td>never pay</td>\n",
              "      <td>never pay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>water_quality</th>\n",
              "      <td>soft</td>\n",
              "      <td>soft</td>\n",
              "      <td>soft</td>\n",
              "      <td>soft</td>\n",
              "      <td>soft</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>quality_group</th>\n",
              "      <td>good</td>\n",
              "      <td>good</td>\n",
              "      <td>good</td>\n",
              "      <td>good</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>quantity</th>\n",
              "      <td>enough</td>\n",
              "      <td>insufficient</td>\n",
              "      <td>enough</td>\n",
              "      <td>dry</td>\n",
              "      <td>seasonal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>quantity_group</th>\n",
              "      <td>enough</td>\n",
              "      <td>insufficient</td>\n",
              "      <td>enough</td>\n",
              "      <td>dry</td>\n",
              "      <td>seasonal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>source</th>\n",
              "      <td>spring</td>\n",
              "      <td>rainwater harvesting</td>\n",
              "      <td>dam</td>\n",
              "      <td>machine dbh</td>\n",
              "      <td>rainwater harvesting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>source_type</th>\n",
              "      <td>spring</td>\n",
              "      <td>rainwater harvesting</td>\n",
              "      <td>dam</td>\n",
              "      <td>borehole</td>\n",
              "      <td>rainwater harvesting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>source_class</th>\n",
              "      <td>groundwater</td>\n",
              "      <td>surface</td>\n",
              "      <td>surface</td>\n",
              "      <td>groundwater</td>\n",
              "      <td>surface</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>waterpoint_type</th>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>communal standpipe multiple</td>\n",
              "      <td>communal standpipe multiple</td>\n",
              "      <td>communal standpipe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>waterpoint_type_group</th>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>communal standpipe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>status_group</th>\n",
              "      <td>functional</td>\n",
              "      <td>functional</td>\n",
              "      <td>functional</td>\n",
              "      <td>non functional</td>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             0  ...                        4\n",
              "id                                       69572  ...                    19728\n",
              "amount_tsh                                6000  ...                        0\n",
              "date_recorded                       2011-03-14  ...               2011-07-13\n",
              "funder                                   Roman  ...              Action In A\n",
              "gps_height                                1390  ...                        0\n",
              "installer                                Roman  ...                  Artisan\n",
              "longitude                              34.9381  ...                  31.1308\n",
              "latitude                              -9.85632  ...                 -1.82536\n",
              "wpt_name                                  none  ...                  Shuleni\n",
              "num_private                                  0  ...                        0\n",
              "basin                               Lake Nyasa  ...            Lake Victoria\n",
              "subvillage                            Mnyusi B  ...               Kyanyamisa\n",
              "region                                  Iringa  ...                   Kagera\n",
              "region_code                                 11  ...                       18\n",
              "district_code                                5  ...                        1\n",
              "lga                                     Ludewa  ...                  Karagwe\n",
              "ward                                  Mundindi  ...               Nyakasimbi\n",
              "population                                 109  ...                        0\n",
              "public_meeting                            True  ...                     True\n",
              "recorded_by            GeoData Consultants Ltd  ...  GeoData Consultants Ltd\n",
              "scheme_management                          VWC  ...                      NaN\n",
              "scheme_name                              Roman  ...                      NaN\n",
              "permit                                   False  ...                     True\n",
              "construction_year                         1999  ...                        0\n",
              "extraction_type                        gravity  ...                  gravity\n",
              "extraction_type_group                  gravity  ...                  gravity\n",
              "extraction_type_class                  gravity  ...                  gravity\n",
              "management                                 vwc  ...                    other\n",
              "management_group                    user-group  ...                    other\n",
              "payment                           pay annually  ...                never pay\n",
              "payment_type                          annually  ...                never pay\n",
              "water_quality                             soft  ...                     soft\n",
              "quality_group                             good  ...                     good\n",
              "quantity                                enough  ...                 seasonal\n",
              "quantity_group                          enough  ...                 seasonal\n",
              "source                                  spring  ...     rainwater harvesting\n",
              "source_type                             spring  ...     rainwater harvesting\n",
              "source_class                       groundwater  ...                  surface\n",
              "waterpoint_type             communal standpipe  ...       communal standpipe\n",
              "waterpoint_type_group       communal standpipe  ...       communal standpipe\n",
              "status_group                        functional  ...               functional\n",
              "\n",
              "[41 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 1072
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xH29I3yeQbE4"
      },
      "source": [
        "Get the data types of the values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QwrQ-sMNrWw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2d49043-d504-428a-e1b8-63fa17c542b0"
      },
      "source": [
        "train_data.dtypes"
      ],
      "execution_count": 1073,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                         int64\n",
              "amount_tsh               float64\n",
              "date_recorded             object\n",
              "funder                    object\n",
              "gps_height                 int64\n",
              "installer                 object\n",
              "longitude                float64\n",
              "latitude                 float64\n",
              "wpt_name                  object\n",
              "num_private                int64\n",
              "basin                     object\n",
              "subvillage                object\n",
              "region                    object\n",
              "region_code                int64\n",
              "district_code              int64\n",
              "lga                       object\n",
              "ward                      object\n",
              "population                 int64\n",
              "public_meeting            object\n",
              "recorded_by               object\n",
              "scheme_management         object\n",
              "scheme_name               object\n",
              "permit                    object\n",
              "construction_year          int64\n",
              "extraction_type           object\n",
              "extraction_type_group     object\n",
              "extraction_type_class     object\n",
              "management                object\n",
              "management_group          object\n",
              "payment                   object\n",
              "payment_type              object\n",
              "water_quality             object\n",
              "quality_group             object\n",
              "quantity                  object\n",
              "quantity_group            object\n",
              "source                    object\n",
              "source_type               object\n",
              "source_class              object\n",
              "waterpoint_type           object\n",
              "waterpoint_type_group     object\n",
              "status_group              object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 1073
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdDoRe5AQ-w-"
      },
      "source": [
        "# train_data['status_group'].value_counts()"
      ],
      "execution_count": 1074,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMa4HEE1lmdB"
      },
      "source": [
        "# **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCdgaFvb63b3"
      },
      "source": [
        " **Drop identical or unnecessary columns**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZDQF0xCyrTJ"
      },
      "source": [
        "1. The features **quantity** and **quantity_group** are described as **The quantity of water** So we need to check whether they are same in or not"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j42Ij44M2nQ8"
      },
      "source": [
        "# train_data['quantity'].value_counts()"
      ],
      "execution_count": 1075,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PHl9wv8yL7s"
      },
      "source": [
        "# train_data['quantity_group'].value_counts()"
      ],
      "execution_count": 1076,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKBPh1-C43F2"
      },
      "source": [
        "# train_data.groupby(['quantity','quantity_group']).count()"
      ],
      "execution_count": 1077,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHl0EFnc23Jq"
      },
      "source": [
        "As both features carry identical values we can drop either **quantity** or **quantity_group**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2WZ2F-s7Tc4"
      },
      "source": [
        "2. The features **water_quality** and **quality_group** are described as **The quality of the water** So we need to check whether they are same in or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTnfaJoezKht"
      },
      "source": [
        "# train_data['water_quality'].value_counts()"
      ],
      "execution_count": 1078,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfOJOAxezPet"
      },
      "source": [
        "# train_data['quality_group'].value_counts()"
      ],
      "execution_count": 1079,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaMfhZHS8BON"
      },
      "source": [
        "# train_data.groupby(['water_quality','quality_group']).count()"
      ],
      "execution_count": 1080,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbdFRMUm8meP"
      },
      "source": [
        "As both features have almost same values we can drop either one of them. **water_quality** is more informative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWx4WrQr9Z3x"
      },
      "source": [
        "3. The features **payment** and **payment_type** are described as **What the water costs** So we need to check whether they are same in or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzzVfYpQ9FKs"
      },
      "source": [
        "# train_data['payment'].value_counts()"
      ],
      "execution_count": 1081,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkU5yKVs9k1J"
      },
      "source": [
        "# train_data['payment_type'].value_counts()"
      ],
      "execution_count": 1082,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh5G2YEP9ljQ"
      },
      "source": [
        "# train_data.groupby(['payment','payment_type']).count()"
      ],
      "execution_count": 1083,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlOGDvMz93ot"
      },
      "source": [
        "As both features carry identical values we can drop either **payment** or **payment_type**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7bFhQbU-KQk"
      },
      "source": [
        "4. The features **waterpoint_type** and **waterpoint_type_group** are described as **The kind of waterpoint** So we need to check whether they are same in or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xvl1Egko-jjx"
      },
      "source": [
        "# train_data['waterpoint_type'].value_counts()"
      ],
      "execution_count": 1084,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrcwSsr7-mO1"
      },
      "source": [
        "# train_data['waterpoint_type_group'].value_counts()"
      ],
      "execution_count": 1085,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4AyMc-T-mxB"
      },
      "source": [
        "# train_data.groupby(['waterpoint_type','waterpoint_type_group']).count()"
      ],
      "execution_count": 1086,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ltk40_cN-6lr"
      },
      "source": [
        "As both features have almost same values we can drop either one of them. **waterpoint_type** is more informative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M7knTKZqSr9"
      },
      "source": [
        "5. The features **source** , **source_type** and **source_group** are described as **The source of the water** So we need to check whether they are same in or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1jRktEmpECB"
      },
      "source": [
        "# train_data['source'].value_counts()"
      ],
      "execution_count": 1087,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avkRwFxLqABr"
      },
      "source": [
        "# train_data['source_type'].value_counts()"
      ],
      "execution_count": 1088,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Idq1xHeQqqHK"
      },
      "source": [
        "# train_data['source_class'].value_counts()"
      ],
      "execution_count": 1089,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ChOva5zqDBF"
      },
      "source": [
        "# train_data.groupby(['source_class','source_type','source']).count()"
      ],
      "execution_count": 1090,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImNL2B5Or8Zi"
      },
      "source": [
        " As **source_class** and **source_type** are super sets of **source**, we can drop **source_class** and **source_type**. **source** is more informative feature among them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNdD37xes27Z"
      },
      "source": [
        "6. The features **management** and **management_group** are described as **How the waterpoint is managed** So we need to check whether they are same in or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKXcfiHatQG6"
      },
      "source": [
        "# train_data['management'].value_counts()"
      ],
      "execution_count": 1091,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "of-Y76frtQ1y"
      },
      "source": [
        "# train_data['management_group'].value_counts()"
      ],
      "execution_count": 1092,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSDK6FWGtXpG"
      },
      "source": [
        "# train_data.groupby(['management_group','management']).count()"
      ],
      "execution_count": 1093,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuMW8wtbtlh1"
      },
      "source": [
        "**management** and **management_group** contains same information and management is more detailed. so **management_group** can be dropped"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgTrecMSt5VN"
      },
      "source": [
        "7. The features **extraction_type** , **extraction_type_class** and **extraction_type_group** are described as **The kind of extraction the waterpoint uses** So we need to check whether they are same in or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FI48g4vUtkMt"
      },
      "source": [
        "# train_data['extraction_type'].value_counts()"
      ],
      "execution_count": 1094,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TCsBmX1uJZj"
      },
      "source": [
        "# train_data['extraction_type_class'].value_counts()"
      ],
      "execution_count": 1095,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKPRin3PuJ43"
      },
      "source": [
        "# train_data['extraction_type_group'].value_counts()"
      ],
      "execution_count": 1096,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV8X9l9HuYQo"
      },
      "source": [
        "# train_data.groupby(['extraction_type_class','extraction_type_group','extraction_type']).count()"
      ],
      "execution_count": 1097,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TvF9aOOu0fu"
      },
      "source": [
        "As **extraction_type** contains unique information we can drop **extraction_type_group** and **extraction_type_class**\t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6G_DnF3vCMG"
      },
      "source": [
        "8. The features **scheme_management** and **scheme_name** are described as **Who operates the waterpoint** So we need to check whether they are same in or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w5sEFTjvUnW"
      },
      "source": [
        "# train_data['scheme_management'].value_counts()"
      ],
      "execution_count": 1098,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYS3eFa1vXdX"
      },
      "source": [
        "# train_data['scheme_name'].value_counts()"
      ],
      "execution_count": 1099,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRxy24Iqhs52"
      },
      "source": [
        "# train_data.groupby(['scheme_management','scheme_name']).count()"
      ],
      "execution_count": 1100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AOq9YRrq4gQ"
      },
      "source": [
        "9. The feature **recorded_by** can be dropped as it has only one distinct value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8Few4fZqvSY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2b134e7-a63c-4aee-df8e-46d306eaa718"
      },
      "source": [
        "train_data['recorded_by'].value_counts()"
      ],
      "execution_count": 1101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GeoData Consultants Ltd    59400\n",
              "Name: recorded_by, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 1101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDy8e9IbjD_j"
      },
      "source": [
        "10. The feature **region** can be dropped as there is another feature **region_code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqZ7N61WjSDE",
        "outputId": "d063d9cd-f34a-4a21-9620-ade278ab9ee3"
      },
      "source": [
        "train_data['region'].value_counts()"
      ],
      "execution_count": 1102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Iringa           5294\n",
              "Shinyanga        4982\n",
              "Mbeya            4639\n",
              "Kilimanjaro      4379\n",
              "Morogoro         4006\n",
              "Arusha           3350\n",
              "Kagera           3316\n",
              "Mwanza           3102\n",
              "Kigoma           2816\n",
              "Ruvuma           2640\n",
              "Pwani            2635\n",
              "Tanga            2547\n",
              "Dodoma           2201\n",
              "Singida          2093\n",
              "Mara             1969\n",
              "Tabora           1959\n",
              "Rukwa            1808\n",
              "Mtwara           1730\n",
              "Manyara          1583\n",
              "Lindi            1546\n",
              "Dar es Salaam     805\n",
              "Name: region, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 1102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChP_vZWDo-Ul"
      },
      "source": [
        "Definition for drop columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3Klk9eInk4I"
      },
      "source": [
        "def drop_columns(dataset: pd.DataFrame):\n",
        "  drop_columns=['management_group','scheme_management',\n",
        "                'quantity_group','source_class',\n",
        "                'source_type','recorded_by','quality_group',\n",
        "                'payment_type','extraction_type_class',\n",
        "                'extraction_type', 'waterpoint_type_group','region_code','amount_tsh','num_private']\n",
        "  dataset.drop(drop_columns,1, inplace=True)"
      ],
      "execution_count": 1103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kDcOfXapy0X"
      },
      "source": [
        "drop_columns(train_data)\n",
        "drop_columns(Xtest)"
      ],
      "execution_count": 1104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgmKARiKpfV-"
      },
      "source": [
        "**Handling Null Vaues**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35mIRkvHl5IU"
      },
      "source": [
        "Get the count of null values  in each features "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgHL_Budl2l5"
      },
      "source": [
        "# train_data.isnull().sum()"
      ],
      "execution_count": 1105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv_3dlUvmEyW"
      },
      "source": [
        "Analyzing the data values of the features which have missinng values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uoq1hMXxnBrr"
      },
      "source": [
        "# train_data['funder'].value_counts().head(20)"
      ],
      "execution_count": 1106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoq6qJrrnSNU"
      },
      "source": [
        "# train_data['installer'].value_counts().head(20)"
      ],
      "execution_count": 1107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edqJVVRBnXoo"
      },
      "source": [
        "# train_data['scheme_name'].value_counts().head(20)"
      ],
      "execution_count": 1108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOI1DmGRotn4"
      },
      "source": [
        "missing values in **funder** ,**installer** and **scheme_name** can be filled as **n/a**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfXS8gIHniWd"
      },
      "source": [
        "# train_data['public_meeting'].value_counts().head(20)"
      ],
      "execution_count": 1109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tM6ThfRnovf"
      },
      "source": [
        "# train_data['permit'].value_counts().head(20)"
      ],
      "execution_count": 1110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zgJhYQFoIRG"
      },
      "source": [
        "**public_meeting** and **permit** have nearly 3000 null values and they have value **true** in very high number compared to **false**. so we can fill null values with **true**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKo1_Xf6pmi2"
      },
      "source": [
        "Definition for replace missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrTn3AhHpd9e"
      },
      "source": [
        "def replace_null_value(dataset: pd.DataFrame):\n",
        "    for column in ['funder','installer','scheme_name','subvillage']:\n",
        "        dataset[column] = dataset[column].fillna('n/a')\n",
        "    for column in ['permit','public_meeting']:\n",
        "        dataset[column] = dataset[column].fillna('true')"
      ],
      "execution_count": 1111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGlklDKupp7g"
      },
      "source": [
        "replace_null_value(train_data)\n",
        "replace_null_value(Xtest)"
      ],
      "execution_count": 1112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVI5EK22gQE9"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "def convert_date_columns_to_epoch(dataset: pd.DataFrame, timestamp_format=\"%Y-%m-%d\"):\n",
        "        dataset['date_recorded'] = [ datetime.datetime.strptime(x, timestamp_format).timestamp() for x in dataset['date_recorded']]"
      ],
      "execution_count": 1113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LF1bbJwOgZSE"
      },
      "source": [
        "# convert_date_columns_to_epoch(train_data)\n",
        "# convert_date_columns_to_epoch(Xtest)"
      ],
      "execution_count": 1114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vAONS6nqMHP"
      },
      "source": [
        "**Encoding categorical columns**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7zXuWi0uiI8"
      },
      "source": [
        "train_data['permit'] = train_data['permit'].astype(bool).astype(int)\n",
        "Xtest['permit'] = Xtest['permit'].astype(bool).astype(int)"
      ],
      "execution_count": 1115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiU6fk2euozS"
      },
      "source": [
        "train_data['public_meeting'] = train_data['public_meeting'].astype(bool).astype(int)\n",
        "Xtest['public_meeting'] = Xtest['public_meeting'].astype(bool).astype(int)"
      ],
      "execution_count": 1116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOgDCFiPs6Oc"
      },
      "source": [
        "cat_cols = train_data.select_dtypes('object').columns"
      ],
      "execution_count": 1117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baYrNyzqtqkJ"
      },
      "source": [
        "def encode_categorical_columns(dataset: pd.DataFrame) -> Dict[str, LabelEncoder]:\n",
        "    encoders = {} \n",
        "    for column in cat_cols:\n",
        "      if column not in dataset.columns:\n",
        "        continue\n",
        "\n",
        "      le = LabelEncoder()\n",
        "      le.fit(dataset[column])\n",
        "\n",
        "      dataset[column] = le.transform(dataset[column])\n",
        "      encoders[column]= le\n",
        "        \n",
        "    return encoders"
      ],
      "execution_count": 1118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtYbRuH1t1rx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f46dd0b-b32a-4e76-aba1-e45f42c13b5a"
      },
      "source": [
        "encoders = encode_categorical_columns(train_data)\n",
        "encode_categorical_columns(Xtest)"
      ],
      "execution_count": 1119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'basin': LabelEncoder(),\n",
              " 'date_recorded': LabelEncoder(),\n",
              " 'extraction_type_group': LabelEncoder(),\n",
              " 'funder': LabelEncoder(),\n",
              " 'installer': LabelEncoder(),\n",
              " 'lga': LabelEncoder(),\n",
              " 'management': LabelEncoder(),\n",
              " 'payment': LabelEncoder(),\n",
              " 'quantity': LabelEncoder(),\n",
              " 'region': LabelEncoder(),\n",
              " 'scheme_name': LabelEncoder(),\n",
              " 'source': LabelEncoder(),\n",
              " 'subvillage': LabelEncoder(),\n",
              " 'ward': LabelEncoder(),\n",
              " 'water_quality': LabelEncoder(),\n",
              " 'waterpoint_type': LabelEncoder(),\n",
              " 'wpt_name': LabelEncoder()}"
            ]
          },
          "metadata": {},
          "execution_count": 1119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oALfS7RCtwIA"
      },
      "source": [
        "**Scale columns**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhPgZfRmtyko"
      },
      "source": [
        "def scale_columns(dataset: pd.DataFrame):\n",
        "    scaler = StandardScaler()\n",
        "    dataset = scaler.fit_transform(dataset)"
      ],
      "execution_count": 1120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZEGvR6Utz5e"
      },
      "source": [
        "scale_columns(train_data)\n",
        "scale_columns(Xtest)"
      ],
      "execution_count": 1121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_o9fGE3yuLGT"
      },
      "source": [
        "Split data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3w7hyEfuPAT"
      },
      "source": [
        "X = train_data.iloc[:, :-1]\n",
        "X.drop('id',1)\n",
        "y = train_data.iloc[:, -1]\n",
        "# to divide our X and y to test and train\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.00000001, random_state=42)"
      ],
      "execution_count": 1122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIPW_j52uHx1"
      },
      "source": [
        "# **Modeling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upiV7N9quNuM"
      },
      "source": [
        "# !pip install catboost"
      ],
      "execution_count": 1123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPleI2htwBzm"
      },
      "source": [
        " **CatBoostClassifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr27u4m1umTT"
      },
      "source": [
        "# from catboost import CatBoostClassifier\n",
        "# model= CatBoostClassifier(\n",
        "#                          learning_rate = 0.39730054363848666,\n",
        "#         # n_estimators=1000,\n",
        "#         subsample=0.075,\n",
        "#         max_depth=5,\n",
        "#         l2_leaf_reg = 40,\n",
        "#         verbose=100,\n",
        "#         bootstrap_type=\"Bernoulli\"\n",
        "#         # auto_class_weights=\"SqrtBalanced\",\n",
        "#         # loss_function='MultiClass'\n",
        "#         )"
      ],
      "execution_count": 1124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pm_ShAyxbRVp"
      },
      "source": [
        "**XGBoost**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjOz7vX4v2l2"
      },
      "source": [
        "# from xgboost import XGBClassifier\n",
        "# model = XGBClassifier(nthread=2, num_class=3, \n",
        "#                         min_child_weight=3, max_depth=15,\n",
        "#                         gamma=0.5, scale_pos_weight=0.8,\n",
        "#                         subsample=0.7, colsample_bytree = 0.8,\n",
        "#                         objective='multi:softmax')"
      ],
      "execution_count": 1125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbot533ZbYKH"
      },
      "source": [
        "**RandomForest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8FFQ98q_9ZF"
      },
      "source": [
        "# from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
        "# model = RandomForestClassifier(max_depth=25,\n",
        "#                                n_estimators = 42*5, \n",
        "#                                criterion = 'entropy',\n",
        "#                                random_state = 0)\n",
        "    "
      ],
      "execution_count": 1126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFoNlXZJbk08"
      },
      "source": [
        "Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twDDVhWRu1Wy"
      },
      "source": [
        "# model.fit(X_train, y_train)\n",
        "# print(model.score(X_test, y_test))"
      ],
      "execution_count": 1127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wnEK4BpvPe5"
      },
      "source": [
        "f1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWeTJD-ju-6R"
      },
      "source": [
        "# from sklearn.metrics import f1_score\n",
        "# train_pred = model.predict(X_test)\n",
        "# f1_score(train_pred, y_test,average = 'macro')"
      ],
      "execution_count": 1128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyzXfRqz8WGO",
        "outputId": "0d3deb5d-6e2a-4e22-9f8f-6bf026b0b019",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        }
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Create a search grid of parameters that will be shuffled through\n",
        "random_grid = {\n",
        "'bootstrap': [True],\n",
        "'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
        "'max_features': ['auto', 'sqrt'],\n",
        "'min_samples_leaf': [1, 2, 4],\n",
        "'min_samples_split': [2, 5, 10],\n",
        "'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]\n",
        "}\n",
        "\n",
        "# Using the random grid and searching for best hyperparameters\n",
        "\n",
        "rf = RandomForestRegressor() #creating base model\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
        "rf_random.fit(X_train, y_train) #fit is to initiate training process"
      ],
      "execution_count": 1133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1133-0e49174cb7a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#creating base model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mrf_random\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distributions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mrf_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#fit is to initiate training process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1483\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT9_3DYj87ro"
      },
      "source": [
        "# from sklearn.model_selection import GridSearchCV\n",
        "# # Create the parameter grid based on the results of random search \n",
        "# param_grid = {\n",
        "#     bootstrap: [True],\n",
        "#     max_depth: [80, 90, 100, 110],\n",
        "#     max_features: [2, 3],\n",
        "#     min_samples_leaf: [3, 4, 5],\n",
        "#     min_samples_split: [8, 10, 12],\n",
        "#     n_estimators: [100, 200, 300, 1000]\n",
        "# }\n",
        "# rf = RandomForestRegressor()\n",
        "\n",
        "# Instantiate the grid search model\n",
        "\n",
        "# grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
        "\n",
        "#                           cv = 3, n_jobs = -1, verbose = 2)\n",
        "\n",
        "\n",
        "# # Fit the grid search to the data\n",
        "# grid_search.fit(train_features, train_labels)\n",
        "# grid_search.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBxLDWgr5GzT"
      },
      "source": [
        "# id = Xtest['id']\n",
        "# Xtest.drop('id',1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loN9U4ClxPIZ"
      },
      "source": [
        "# val_pred = model.predict(Xtest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9OWFzap41zC"
      },
      "source": [
        "# status_group_encoder = encoders['status_group']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G58SlPYF43LF"
      },
      "source": [
        "# real_decoded_y = pd.DataFrame(status_group_encoder.inverse_transform(val_pred), columns = ['status_group'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czoi3vHG48Xz"
      },
      "source": [
        "# result = pd.concat([id, real_decoded_y], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_5FNNUV498t"
      },
      "source": [
        "# result.to_csv(\"submisssion.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}